---
title: "Lab 3"
author: "Damian Ke & Kyriakos Papadopoulos"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Assignment 1. KERNEL METHODS
Implement a kernel method to predict the hourly temperatures for a date and place in Sweden.
To do so, you are provided with the files stations.csv and temps50k.csv. These
files contain information about weather stations and temperature measurements in the stations
at different days and times. The data have been kindly provided by the Swedish Meteorological
and Hydrological Institute (SMHI).
You are asked to provide a temperature forecast for a date and place in Sweden. The
forecast should consist of the predicted temperatures from 4 am to 24 pm in an interval of 2
hours. Use a kernel that is the sum of three Gaussian kernels:
Y The first to account for the physical distance from a station to the point of interest. For
this purpose, use the function distHaversine from the R package geosphere.
Y The second to account for the distance between the day a temperature measurement
was made and the day of interest.
Y The third to account for the distance between the hour of the day a temperature measurement
was made and the hour of interest.
Choose an appropriate smoothing coefficient or width for each of the three kernels above.
No cross-validation should be used. Instead, choose manually a width that gives large kernel
values to closer points and small values to distant points. Show this with a plot of the kernel
value as a function of distance. Help: Note that the file temps50k.csv may contain temperature
measurements that are posterior to the day and hour of your forecast. You must filter
such measurements out, i.e. they cannot be used to compute the forecast.
Finally, repeat the exercise above by combining the three kernels into one by multiplying
them, instead of summing them up. Compare the results obtained in both cases and elaborate
on why they may differ.
The only R package that is allowed to solve this assignment is the geosphere package
(specifically, the function distHaversine). Feel free to use the template below to solve the
assignment.

```{r, echo=FALSE}
set.seed(1234567890)
library(ggplot2)
library(geosphere)
#Else could not read the file, required fileEncoding
#Changed to read.csv2 to be able to read.
stations <- read.csv2("stations.csv",fileEncoding = "windows-1258")
temps <- read.csv("temps50k.csv")
st <- merge(stations,temps,by="station_number")


# These three values are up to the students
h_distance <- 40
h_date <- 1460
h_time <- 2

#The point to predict (up to the students) - Falun-Lugnet
a <- 60.619 
b <- 15.6603

date_predicted <- "2007-10-08" # The date to predict (up to the students)
times <- c("04:00:00", "06:00:00", "08:00:00","10:00:00","12:00:00","14:00:00",
           "16:00:00","18:00:00","20:00:00","22:00:00","24:00:00")

# Studentsâ€™ code here
#Filtering data
filtered_data = subset(st, as.Date(date) < as.Date(date_predicted))

#Converting columns to correct type
filtered_data$time = strptime(filtered_data$time, format="%H:%M:%S")
filtered_data$longitude = as.numeric(filtered_data$longitude)
filtered_data$latitude = as.numeric(filtered_data$latitude)


#Adding 3 Kernels

#Kernel 1
#The first to account for the physical distance from a station to the point of interest. For
#this purpose, use the function distHaversine from the R package geosphere.

#Calculated in meters --> Divided by 1000 to get in km
distance_difference = distHaversine(c(b,a),rev(filtered_data[,4:5]))/1000


#Kernel 2
# The second to account for the distance between the day a temperature measurement
#was made and the day of interest.
day_difference = as.numeric(as.Date(date_predicted)-as.Date(filtered_data$date))

#Kernel 3
#The third to account for the distance between the hour of the day a temperature measurement was made 
#and the hour of interest.
time_difference = matrix(nrow=nrow(filtered_data),ncol=length(times))
i=1
#For loop to calculate the difference for each hourly temperature.
for (time in times){
  time_difference[,i] = abs(as.integer(difftime(strptime(time,format="%H:%M:%S"),
                                               filtered_data$time, units="hours")))
  
  i=i+1
}
#Issue that prediction goes up for time difference after 12.
time_difference = ifelse(time_difference >12, 24-time_difference, time_difference)

#Calculations of Gaussian kernels with kernel trick
results_distance = exp(((-distance_difference**2)/(2*(h_distance**2))))
results_day = exp(((-day_difference**2)/(2*(h_date**2))))
results_time = exp(((-time_difference**2)/(2*(h_time**2))))

#Addition Predictions
pred_added = (results_distance+results_day+results_time)

results_added= matrix()
#Loop to calculate the prediction for each hour.
for(i in 1:length(times)){
  results_added[i] = sum(pred_added[,i]*filtered_data$air_temperature)/sum(pred_added[,i])
}


#Multiplied
pred_multiplied = (results_distance*results_day*results_time)

results_multiplied = matrix()
for(i in 1:length(times)){
  results_multiplied[i] = sum(pred_multiplied[,i]*filtered_data$air_temperature)/sum(pred_multiplied[,i])
}

#Plot the results
plot_df_sum_add = data.frame(results_added, results_multiplied,times)
colnames(plot_df_sum_add) = c("Added", "Multiplied","Times")

plot_df_sum_add = ggplot(plot_df_sum_add, aes(x=as.factor(substr(Times,1,5))))+
  geom_point(aes(y=Added, color="Added Kernel"))+
  geom_point(aes(y=Multiplied, color="Multiplied Kernel"))+
  xlab("Time")+
  ylab("Prediction")+
  ggtitle("Prediction for Added and Multiplied Kernels")+
  scale_color_manual(name="Definitions", values=c("Added Kernel"="red", 
                                                  "Multiplied Kernel"="blue"))

```

## Question 1
Choose manually a width that gives large kernel values to closer points and small values to distant points
Show this with a plot of the kernel value as a function of distance.


```{r, echo=FALSE}
#Plot of results vs distance
plot_df_3 = data.frame(results_distance, distance_difference)
colnames(plot_df_3) = c("Value", "Distance")

ggplot(plot_df_3, aes(x=Distance,y=Value))+
  geom_line()+
  xlab("Distance Difference")


plot_df_4 = data.frame(results_day, day_difference)
colnames(plot_df_4) = c("Value", "Distance")

ggplot(plot_df_4, aes(x=Distance,y=Value))+
  geom_line()+
  xlab("Day Difference")


plot_df_5 = data.frame(results_time[,11], time_difference[,11])
colnames(plot_df_5) = c("Value", "Distance")

ggplot(plot_df_5, aes(x=Distance,y=Value))+
  geom_line()+
  xlab("Time Difference")

```

**Answer**

The chosen kernels widths are:
Distance : `r h_distance`

Date : `r h_date`

Time : `r h_time`

Important to mention that distance was divided by 1000 to get the distance into Kilometers.
Therefore, the width of distance was set to 40km which seemed to give reasonable values.

The width was set to 1460 so it can find affected by temperature increase for each year.
For this exercise, the date was also tested on difference with modulo 365. The method of
modulo 365 gave better results as it better predicted seasonal temperature differences.
But as this method may be outside of the scope of this lab, therefore the total day difference
was used.

Lastly, for time difference if values were larger than 12, then it would calculate 24-time difference to get
correct values. Else there would be an increase of temperature at about hours 18-24.
The width of time was set to 2, which seemed to be better at predicting the temperature
at different times.

## Question 2 
Compare the results obtained in both cases and elaborate
on why they may differ.

```{r, echo=FALSE}
plot_df_sum_add
```

**Answer**
Chosen location is (60.619, 15.6603) which is Falun-Lugnet.
The predicted date is "2007-10-08". The chosen location and date was used to predict
the actual temperature within the dataset. 
For date "2007-10-08" at time 06.00 the temperature was 6.9 degrees.
Which shows that both methods were quite far to the predicted value.

As it can be seen in the figure, the multiplied kernel has higher prediction values than
the added one. Also there seem to be smaller temperature variation in the added kernel, meanwhile
the multiplied one has higher variance. 
For added kernel, each kernel has their own value which is not impacted by values from the other
kernels. For the multiplied kernel, each kernel impact the value of the others as they are multiplied.
Therefore, values of the kernels has a bigger impact on the total prediction which is
why there is a difference between these kernels.

In addition, kernels width have impact on these results, as the graph lines in question 1 impact the total prediction.
For larger values of the width, additional kernel differences will have larger kernel values and will therefore 
impact the kernel.
Meanwhile for small values of width, the large kernel values will have less value and therefore
have smaller impact on the kernel.


## Assigment 3: Neural Networks

```{r, include=FALSE}
library(neuralnet)

mean_square_error <- function(y_hat, y){
  res <- mean((y_hat - y) ^ 2)
  return(res)
}

set.seed(1234567890)
```

### Question 1: 
Train a neural network to learn the trigonometric sine function. To do so, sample 
500 points uniformly at random in the interval [0,10]. Apply the sine function to 
each point. The resulting value pairs are the data points available to you. Use 
25 of the 500 points for training and the rest for test. Use one hidden layer with 
10 hidden units. You do not need to apply early stopping. Plot the training and 
test data, and the predictions of the learned NN on the test data. You should get 
good results. Comment your results.

**Answer 1:**

```{r, include=FALSE}
Var <- runif(500, 0, 10)
mydata <- data.frame(Var, Sin=sin(Var))
tr <- mydata[1:25,] # Training
te <- mydata[26:500,] # Test
```

```{r, echo=FALSE}


winit <- runif(31, -1, 1)# Your code here
nn <- neuralnet(Sin ~ Var, tr, hidden = 10, startweights = winit)
plot(tr, cex=2)
points(te, col = "blue", cex=1)
points(te[,1],predict(nn,te), col="red", cex=1)

mse1 = mean_square_error(predict(nn, te), te[, 2])

```

According to the plot and the MSE error, as we have a regression problem, our model
predicts the real values with a very a high accuracy and that's why the MSE error
is roundly 0.002 on the test dataset.


We need to initialize 31 weights. The number of weights
occurs from the first 10 that they are needed from the input to the hidden layer.
Also, every neuron of the hidden layer needs intercept as well so we have to add 
10 more weights. From the hidden layer to the output we need 10 weights and 1 
intercept as we have only 1 neuron as the final output. In total it's 31.

### Question 2: 
In question (1), you used the default logistic (a.k.a. sigmoid) activation function, i.e.
act.fct = "logistic". Repeat question (1) with the following custom activation
functions: h1(x) = x, h2(x) = max{0, x} and h3(x) = ln(1 + exp x) (a.k.a. linear, ReLU
and softplus). See the help file of the neuralnet package to learn how to use custom
activation functions. Plot and comment your results.

**Answer 2:**

```{r}
# Defining the custom functions

# Linear
h1 <- function(x){
  x
}

# Relu
h2 <- function(x){
  ifelse(0 < x, x, 0)
}

# Softplus
h3 <- function(x){
  log(1 + exp(x), base = exp(1))
}
```

- For activation function = Linear 

```{r, echo=FALSE}
nn_h1 <- neuralnet(Sin ~ Var, tr, hidden = 10, startweights = winit, act.fct = h1)
plot.new()
plot(tr, cex=2)
points(te, col = "blue", cex=1)
points(te[,1],predict(nn_h1,te), col="red", cex=1)
```
The predictions of our model follow a straight line around 0.3. That's because 
we don't actually use any activation function and the output is only the sum of 
the weights. 

- For activation function = Softplus

```{r, echo=FALSE}
nn_h3 <- neuralnet(Sin ~ Var, tr, hidden = 10, startweights = winit, 
                   act.fct = h3)
plot.new()
plot(tr, cex=2)
points(te, col = "blue", cex=1)
points(te[,1],predict(nn_h3,te), col="red", cex=1)
```
The neural network using softplus as the activation function has very good results.

- For activation function = ReLu

```{r, echo=FALSE}
nn_h2 <- neuralnet(Sin ~ Var, tr, hidden = 10, startweights = winit, 
                   act.fct = h2)
plot.new()
plot(tr, cex=2)
points(te, col = "blue", cex=1)
points(te[,1],predict(nn_h2,te), col="red", cex=1)
```

We can't define Relu as max(0,x) as an activation function because R will throw us an error. That's because Relu isn't differentiable in X = 0 and that causes a problem to the backpropagation. Backpropagation computes the gradient of the loss function with respect to each weight by the chain rule, so that's why it can't handle the case that a point (x = 0) is not differentiable. Searching in the documentation of R we found out that we can use ifelse command for this case. Our model follows the true prediction in a very good way but after roundly 4 our predictions become linear.

### Question 3:

Sample 500 points uniformly at random in the interval [0,50], and apply the sine function to each point. Use the NN learned in question (1) to predict the sine function value
for these new 500 points. You should get mixed results. Plot and comment your results.

**Answer 3: **
```{r, echo=FALSE, warning=FALSE}
x <- runif(500, 0, 50)
x_te <- mydata[1:500,] # Test
data <- data.frame(Var = x, Sin=sin(x))


plot.new()
plot(data[, 1], data[, 2], cx=1)
points(x ,predict(nn, data), col="red")
predictions = predict(nn, data)
```
our model make accurate predictions for the interval of 1-10. For 10-50 the are much different than -1 to 1 and that's why they are not shown in the graph.

### Question4:
 In question (3), the predictions seem to converge to some value. Explain why this
happens. To answer this question, you may need to get access to the weights of the

**Answer 4: **

Because the model was trained for inputs from 0 - 10 the weights 
are specified for these values. Because we use sigmoid function as the activation function of our neural net, the output of each neuro for very big values it will be 1 and for very small values it will be 0. So because the values of weights are small for values > 10
every neuron give us 0 or 1 after the first layer. So every neuron, in the hidden layer, that has negative weight it will output 0. On the other hand the neurons, in the hidden layer, with positive weight will output 1. So the output will be the sum of the neurons in the hidden layer that has positive sign multiplied by the weights to the final output plus the intercept 

**Question 5: **
Sample 500 points uniformly at random in the interval [0,10], and apply the sine function to each point. Use all these points as training points for learning a NN that tries to predict x from sin(x), i.e. unlike before when the goal was to predict sin(x) from x. Use the learned NN to predict the training data. You should get bad results. Plot and comment your results. Help: Some people get a convergence error in this question. It can be solved by stopping the training before reaching convergence by setting
threshold = 0.1.

```{r}
Sx <- runif(500, 0, 10)
data2 <- data.frame(Sx, Sin=sin(Sx))
nn5 <- neuralnet(Sx ~ Sin, data2, hidden = 10, startweights = winit, threshold = 0.1)

plot.new()
plot(x = data2$Sin, y = data2$Sx, cex=2, col = "blue")
points(x = data2$Sin, y = predict(nn5,data2), col="red", cex=1)
```

This can easily explained as we can see from the plot there are values in x axis
that have same values at y axis. That's why our output is not good at all as is 
difficult for the neural network to define weights capable of predictin the same y
for different x

```{r, echo=FALSE}
cat("The mean square error for question 5 is: ", mean_square_error(x, predict(nn5, data2))
)
```


# Appendix
```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```